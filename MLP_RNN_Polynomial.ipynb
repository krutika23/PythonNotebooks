{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##MLP with TF Tuner implementation"
      ],
      "metadata": {
        "id": "OXg34tqrF3hA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU1SuStEVdvE",
        "outputId": "78fa507d-d2f0-48ed-a59b-8e39bae897ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.4.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.29.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.51.1)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.7/135.7 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install -q -U keras-tuner\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files=np.load('/content/drive/MyDrive/Data/689PolynomialData/ae_data.npz')\n",
        "for k in files:\n",
        "  print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2WlgCqoVmyt",
        "outputId": "44af0493-dd2f-4316-9e56-fe1873fc608d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Str\n",
            "Xtr\n",
            "Ytr\n",
            "Ste\n",
            "Xte\n",
            "Yte\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files['Ytr'][0],files['Str'][20:40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfPamGFhV0j0",
        "outputId": "d1b07b6e-33af-4b5f-b975-25a45ee4ad5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-188.]),\n",
              " array(['    9-8', '  1+489', '    6+1', ' 239+53', '   2+78', '   5-40',\n",
              "        '    4+9', '  7+273', ' 349-44', '  73+40', '205+152', '    7-5',\n",
              "        '  59-31', ' 696-70', '   47+7', '    7-8', '   87-0', '   1+69',\n",
              "        '  304-8', ' 78-550'], dtype='<U7'))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx={'':0,'+':1,'-':2}\n",
        "charset=set() #sorted(set(files['Str']))\n",
        "for val in files['Str']:\n",
        "  for e in val: charset.add(e)\n",
        "word2idx={word:idx for idx, word in enumerate(sorted(charset))}"
      ],
      "metadata": {
        "id": "rD6WS0E_Wuaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(data):\n",
        "  return [word2idx[i] for i in data]\n",
        "X=[tokenize(val) for val in files['Str']]\n",
        "X=np.array(X)\n",
        "y=np.array(files['Ytr'])"
      ],
      "metadata": {
        "id": "jkq8jJ-IaF4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=X[:5000]\n",
        "y=y[:5000]"
      ],
      "metadata": {
        "id": "Sp4ZG2MBLc0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2,l1\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import AUC\n",
        "import keras_tuner as kt\n",
        "\n",
        "def model_builder(hp):\n",
        "  model=Sequential()\n",
        "  model.add(Dense(7,input_shape=(7,),activation='relu',kernel_regularizer=l2(0.001)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.15))\n",
        "  model.add(Dense(hp.Int('hidden_size', 30, 100, step=10, default=50),activation='relu'))\n",
        "  # model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(12,activation='relu',kernel_regularizer=l1(0.001)))\n",
        "  # model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1))\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[0.01,0.001,0.0001,0.00001])\n",
        "  optimizer = Adam(lr=hp_learning_rate, decay=5e-4)\n",
        "  model.compile(optimizer=optimizer, loss='mae')\n",
        "  return model\n",
        "# history=model.fit(X, y, epochs=50, validation_split=0.2, batch_size=8)"
      ],
      "metadata": {
        "id": "YzBCUUvJMjqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Implementing TF tuner for hyperparameter tuning"
      ],
      "metadata": {
        "id": "iAACkweSlnO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective=kt.Objective('val_loss',direction=\"min\"),\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir',\n",
        "                     project_name='intro_to_kt')\n",
        "stop_early = EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(X, y, epochs=10, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "J22UrwPuTLYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSPOjEc4TOjD",
        "outputId": "040e6d22-c3a6-431a-9d98-f2de58295287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hidden_size': 30,\n",
              " 'learning_rate': 0.01,\n",
              " 'tuner/epochs': 10,\n",
              " 'tuner/initial_epoch': 0,\n",
              " 'tuner/bracket': 0,\n",
              " 'tuner/round': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(X, y, epochs=50, validation_split=0.2)\n",
        "\n",
        "val_acc_per_epoch = history.history['val_loss']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbBxGJVrpsI3",
        "outputId": "9ff59b0b-a52e-4464-afc9-e68225e46f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 168088.0312 - val_loss: 133251.1406\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 143873.3281 - val_loss: 132857.6094\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 138589.9219 - val_loss: 126886.8438\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 139480.8438 - val_loss: 127596.5781\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 136603.7344 - val_loss: 125184.0781\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 137007.6406 - val_loss: 123711.9844\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 138104.9531 - val_loss: 124451.0703\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 138102.9531 - val_loss: 123321.4062\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 134512.2031 - val_loss: 125478.5156\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 136722.3750 - val_loss: 123820.5156\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 135213.2031 - val_loss: 124808.3516\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 134685.3906 - val_loss: 124641.8203\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 133474.3594 - val_loss: 123383.8828\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 135415.6875 - val_loss: 126582.4141\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 135419.5625 - val_loss: 121974.3281\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 134321.4844 - val_loss: 123080.2578\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 136088.3125 - val_loss: 122407.4375\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 133890.7031 - val_loss: 121973.2344\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 136013.5625 - val_loss: 122654.9297\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 133863.2656 - val_loss: 120655.9062\n",
            "Epoch 21/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 132744.3281 - val_loss: 119538.7734\n",
            "Epoch 22/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 132763.2812 - val_loss: 119471.3203\n",
            "Epoch 23/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 131329.7812 - val_loss: 114418.6406\n",
            "Epoch 24/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 125246.6641 - val_loss: 106723.1250\n",
            "Epoch 25/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 125406.4766 - val_loss: 107652.1875\n",
            "Epoch 26/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 125302.3594 - val_loss: 100367.4141\n",
            "Epoch 27/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 124276.7344 - val_loss: 98920.4609\n",
            "Epoch 28/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 122198.2578 - val_loss: 98432.7812\n",
            "Epoch 29/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 120235.0859 - val_loss: 92945.6328\n",
            "Epoch 30/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 120379.1719 - val_loss: 93694.1719\n",
            "Epoch 31/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 116496.8594 - val_loss: 91426.7656\n",
            "Epoch 32/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 115115.7422 - val_loss: 86000.9844\n",
            "Epoch 33/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 117269.1719 - val_loss: 89584.8438\n",
            "Epoch 34/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 112864.5781 - val_loss: 82688.6562\n",
            "Epoch 35/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 120514.1875 - val_loss: 85134.3984\n",
            "Epoch 36/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 118427.0469 - val_loss: 90670.5469\n",
            "Epoch 37/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 115499.9609 - val_loss: 92233.6641\n",
            "Epoch 38/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 115820.7578 - val_loss: 86526.3281\n",
            "Epoch 39/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 113572.0703 - val_loss: 85839.2109\n",
            "Epoch 40/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 111145.8281 - val_loss: 83032.3828\n",
            "Epoch 41/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 116939.9688 - val_loss: 81965.2266\n",
            "Epoch 42/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 116607.7188 - val_loss: 83430.2188\n",
            "Epoch 43/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 111492.1797 - val_loss: 81330.5703\n",
            "Epoch 44/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 115303.9609 - val_loss: 82878.7031\n",
            "Epoch 45/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 112088.0547 - val_loss: 82948.6484\n",
            "Epoch 46/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 114060.5625 - val_loss: 84161.8516\n",
            "Epoch 47/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 115880.1328 - val_loss: 86485.0469\n",
            "Epoch 48/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 117494.0703 - val_loss: 80307.5156\n",
            "Epoch 49/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 112341.1562 - val_loss: 79930.2656\n",
            "Epoch 50/50\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 110760.4062 - val_loss: 79091.3281\n",
            "Best epoch: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In7xAAFZOL8A",
        "outputId": "15f6bd57-9594-412e-bcaa-763f24bf7a10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[102.95554 ,  26.057236,  81.61793 , 122.64572 , 631.4146  ,\n",
              "         284.43817 ,  26.057236,  26.057236, 659.8656  , 279.8784  ]],\n",
              "       dtype=float32),\n",
              " array([[-188.,   18.,  165., -504.,  889.,  352.,    6.,    9.,  943.,\n",
              "          204.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RNN model"
      ],
      "metadata": {
        "id": "HmVV2CWbF-cg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6aPpIiOF9c9",
        "outputId": "19f7c835-e5f9-4d0b-eaa0-359046344a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_len=int(0.9*len(X))\n",
        "print(\"training length:\",train_len)\n",
        "\n",
        "train_inputs=torch.tensor(X[:train_len])\n",
        "# train_masks=torch.tensor(attention_mask[:train_len])\n",
        "train_label=torch.tensor(y[:train_len])\n",
        "val_inputs=torch.tensor(X[train_len:])\n",
        "# val_masks=torch.tensor(attention_mask[train_len:])\n",
        "val_label=torch.tensor(y[train_len:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7R91CqeH98l",
        "outputId": "486e84d7-cff5-4c96-da01-d48306c2f854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training length: 58320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create tensor datasets\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_label)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size,drop_last=True)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(val_inputs, val_label)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size,drop_last=True)"
      ],
      "metadata": {
        "id": "QommdD3DKDD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "devide=\"cpu\"\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "        super(RNNModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # RNN layers\n",
        "        self.rnn = nn.RNN(\n",
        "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob,\n",
        "            # nonlinearity='relu'\n",
        "            # bidirectional=True\n",
        "        )\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, 32)\n",
        "        self.relu=nn.ReLU()\n",
        "        self.fc1 = nn.Linear(32, 8)\n",
        "        self.relu1=nn.ReLU()\n",
        "        self.fc2=nn.Linear(8, output_dim)\n",
        "        self.sigmoid=nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x=x.unsqueeze(0)\n",
        "        # Initializing hidden state for first input with zeros\n",
        "\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "        h0=h0.to(device)\n",
        "        h0=h0.to(torch.float32)\n",
        "        x=x.to(torch.float32)\n",
        "        x=x.to(device)\n",
        "\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        out, h0 = self.rnn(x, h0)\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "        out = out[: , -1, :]\n",
        "        # return self.fc(out)\n",
        "        # return self.fc1(self.relu(self.fc(out)))\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc2(self.relu1(self.fc1(self.relu(self.fc(out)))))\n",
        "        return out\n",
        "\n",
        "        # out=self.sigmoid(out)\n",
        "        # return out[-1]\n"
      ],
      "metadata": {
        "id": "F5-HnpA-KT_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adam optimizer with weigth decay fixes\n",
        "import torch.optim as optim\n",
        "# from warmup_scheduler_pytorch import WarmUpScheduler\n",
        "model=RNNModel(7,7,3,1,0.1)\n",
        "optimizer = optim.AdamW(model.parameters(),\n",
        "                  lr = 0.001 , # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  # eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n",
        "                  weight_decay=0.001\n",
        "\n",
        "                )\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=15, verbose=True\n",
        ")\n",
        "# scheduler_warmup = WarmUpScheduler(optimizer, multiplier=1, total_epoch=5, after_scheduler=scheduler)\n",
        "\n",
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 8\n",
        "device=\"cpu\"\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# scheduler_warmup = get_linear_schedule_with_warmup(optimizer,\n",
        "#                                             num_warmup_steps = 5, # Default value in run_glue.py\n",
        "#                                             num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7DcCrroMAKP",
        "outputId": "62ae2598-f2c0-4140-d103-fda0504af4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.ReduceLROnPlateau at 0x7f2c9a4dd0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lossFunction(predicted,target):\n",
        "  loss = nn.L1Loss(reduction='mean')\n",
        "  return loss(predicted,target)\n",
        "tr_loss_hist = []\n",
        "\n",
        "\n",
        "model.train()\n",
        "model.to(device)\n",
        "for e in range(150):\n",
        "    avg_tr_loss = []\n",
        "    tr_step = 0\n",
        "\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "        input,label=batch\n",
        "        x_batch = input.view([batch_size, -1, 7]).to(device)\n",
        "        y_batch = label.to(device)\n",
        "        y_batch=y_batch.to(torch.float32)\n",
        "        predicted=model(x_batch)\n",
        "\n",
        "        loss=lossFunction(predicted,y_batch)\n",
        "        avg_tr_loss.append(loss.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        tr_step += 1\n",
        "\n",
        "    atl=sum(avg_tr_loss)/ tr_step\n",
        "    # scheduler.step(atl)\n",
        "    tr_loss_hist.append(atl)\n",
        "\n",
        "    if (e + 1) % 2 == 0:\n",
        "        print('Epoch: {:3}, tr_loss: {:.3f}'.format(e+1, atl))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40SQJGAmMCWc",
        "outputId": "df3f1cc0-b74c-4166-ea73-a64ecbdc51da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   2, tr_loss: 226.627\n",
            "Epoch:   4, tr_loss: 189.183\n",
            "Epoch:   6, tr_loss: 170.296\n",
            "Epoch:   8, tr_loss: 165.633\n",
            "Epoch:  10, tr_loss: 161.580\n",
            "Epoch:  12, tr_loss: 160.019\n",
            "Epoch:  14, tr_loss: 156.660\n",
            "Epoch:  16, tr_loss: 152.372\n",
            "Epoch:  18, tr_loss: 142.985\n",
            "Epoch:  20, tr_loss: 129.768\n",
            "Epoch:  22, tr_loss: 123.630\n",
            "Epoch:  24, tr_loss: 120.423\n",
            "Epoch:  26, tr_loss: 118.487\n",
            "Epoch:  28, tr_loss: 114.768\n",
            "Epoch:  30, tr_loss: 111.457\n",
            "Epoch:  32, tr_loss: 107.907\n",
            "Epoch:  34, tr_loss: 104.736\n",
            "Epoch:  36, tr_loss: 102.520\n",
            "Epoch:  38, tr_loss: 100.491\n",
            "Epoch:  40, tr_loss: 99.905\n",
            "Epoch:  42, tr_loss: 98.813\n",
            "Epoch:  44, tr_loss: 97.388\n",
            "Epoch:  46, tr_loss: 97.960\n",
            "Epoch:  48, tr_loss: 96.032\n",
            "Epoch:  50, tr_loss: 96.258\n",
            "Epoch:  52, tr_loss: 95.065\n",
            "Epoch:  54, tr_loss: 94.958\n",
            "Epoch:  56, tr_loss: 95.399\n",
            "Epoch:  58, tr_loss: 95.160\n",
            "Epoch:  60, tr_loss: 96.062\n",
            "Epoch:  62, tr_loss: 93.586\n",
            "Epoch:  64, tr_loss: 95.381\n",
            "Epoch:  66, tr_loss: 94.109\n",
            "Epoch:  68, tr_loss: 94.054\n",
            "Epoch:  70, tr_loss: 92.809\n",
            "Epoch:  72, tr_loss: 93.866\n",
            "Epoch:  74, tr_loss: 94.200\n",
            "Epoch:  76, tr_loss: 91.936\n",
            "Epoch:  78, tr_loss: 92.350\n",
            "Epoch:  80, tr_loss: 93.880\n",
            "Epoch:  82, tr_loss: 92.385\n",
            "Epoch:  84, tr_loss: 91.471\n",
            "Epoch:  86, tr_loss: 91.638\n",
            "Epoch:  88, tr_loss: 92.385\n",
            "Epoch:  90, tr_loss: 91.154\n",
            "Epoch:  92, tr_loss: 91.233\n",
            "Epoch:  94, tr_loss: 90.972\n",
            "Epoch:  96, tr_loss: 91.950\n",
            "Epoch:  98, tr_loss: 92.349\n",
            "Epoch: 100, tr_loss: 91.548\n",
            "Epoch: 102, tr_loss: 90.744\n",
            "Epoch: 104, tr_loss: 90.547\n",
            "Epoch: 106, tr_loss: 91.703\n",
            "Epoch: 108, tr_loss: 90.395\n",
            "Epoch: 110, tr_loss: 91.769\n",
            "Epoch: 112, tr_loss: 90.622\n",
            "Epoch: 114, tr_loss: 88.908\n",
            "Epoch: 116, tr_loss: 89.942\n",
            "Epoch: 118, tr_loss: 89.698\n",
            "Epoch: 120, tr_loss: 89.459\n",
            "Epoch: 122, tr_loss: 89.474\n",
            "Epoch: 124, tr_loss: 89.008\n",
            "Epoch: 126, tr_loss: 90.270\n",
            "Epoch: 128, tr_loss: 89.473\n",
            "Epoch: 130, tr_loss: 90.782\n",
            "Epoch: 132, tr_loss: 89.657\n",
            "Epoch: 134, tr_loss: 88.865\n",
            "Epoch: 136, tr_loss: 89.046\n",
            "Epoch: 138, tr_loss: 89.800\n",
            "Epoch: 140, tr_loss: 88.830\n",
            "Epoch: 142, tr_loss: 89.808\n",
            "Epoch: 144, tr_loss: 88.070\n",
            "Epoch: 146, tr_loss: 89.483\n",
            "Epoch: 148, tr_loss: 88.229\n",
            "Epoch: 150, tr_loss: 88.627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "avg_val_loss=[]\n",
        "for step,batch in enumerate(validation_dataloader):\n",
        "        input,label=batch\n",
        "        x_batch = input.view([batch_size, -1, 7]).to(device)\n",
        "        y_batch = label.to(device)\n",
        "        y_batch=y_batch.to(torch.float32)\n",
        "\n",
        "        predicted=model(x_batch)\n",
        "        # print(predicted)\n",
        "        print(predicted[:1].T,y_batch[:1].T)\n",
        "        loss=lossFunction(predicted,y_batch)\n",
        "\n",
        "\n",
        "        avg_val_loss.append(loss.item())\n",
        "print(\"Testing Loss: \",sum(avg_val_loss)/len(validation_dataloader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSRzUi9YMf8y",
        "outputId": "d189f082-5a2b-4af1-f481-43b472d210a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-190.4073]], grad_fn=<PermuteBackward0>) tensor([[-581.]])\n",
            "tensor([[56.6208]], grad_fn=<PermuteBackward0>) tensor([[107.]])\n",
            "tensor([[-105.2260]], grad_fn=<PermuteBackward0>) tensor([[-494.]])\n",
            "tensor([[306.9487]], grad_fn=<PermuteBackward0>) tensor([[168.]])\n",
            "tensor([[66.2376]], grad_fn=<PermuteBackward0>) tensor([[21.]])\n",
            "tensor([[68.3400]], grad_fn=<PermuteBackward0>) tensor([[27.]])\n",
            "tensor([[107.1077]], grad_fn=<PermuteBackward0>) tensor([[125.]])\n",
            "tensor([[56.7961]], grad_fn=<PermuteBackward0>) tensor([[71.]])\n",
            "tensor([[724.0518]], grad_fn=<PermuteBackward0>) tensor([[847.]])\n",
            "tensor([[45.5454]], grad_fn=<PermuteBackward0>) tensor([[92.]])\n",
            "tensor([[511.7805]], grad_fn=<PermuteBackward0>) tensor([[506.]])\n",
            "tensor([[1072.7306]], grad_fn=<PermuteBackward0>) tensor([[1171.]])\n",
            "tensor([[-4.0922]], grad_fn=<PermuteBackward0>) tensor([[-76.]])\n",
            "tensor([[631.8201]], grad_fn=<PermuteBackward0>) tensor([[529.]])\n",
            "tensor([[3.5574]], grad_fn=<PermuteBackward0>) tensor([[-37.]])\n",
            "tensor([[3.5201]], grad_fn=<PermuteBackward0>) tensor([[9.]])\n",
            "tensor([[42.4601]], grad_fn=<PermuteBackward0>) tensor([[27.]])\n",
            "tensor([[-347.4615]], grad_fn=<PermuteBackward0>) tensor([[-916.]])\n",
            "tensor([[43.3847]], grad_fn=<PermuteBackward0>) tensor([[91.]])\n",
            "tensor([[3.8235]], grad_fn=<PermuteBackward0>) tensor([[3.]])\n",
            "tensor([[267.2793]], grad_fn=<PermuteBackward0>) tensor([[221.]])\n",
            "tensor([[3.8521]], grad_fn=<PermuteBackward0>) tensor([[-1.]])\n",
            "tensor([[807.0833]], grad_fn=<PermuteBackward0>) tensor([[806.]])\n",
            "tensor([[8.7848]], grad_fn=<PermuteBackward0>) tensor([[44.]])\n",
            "tensor([[816.7145]], grad_fn=<PermuteBackward0>) tensor([[907.]])\n",
            "tensor([[183.1053]], grad_fn=<PermuteBackward0>) tensor([[197.]])\n",
            "tensor([[37.6609]], grad_fn=<PermuteBackward0>) tensor([[64.]])\n",
            "tensor([[390.2960]], grad_fn=<PermuteBackward0>) tensor([[399.]])\n",
            "tensor([[3.8588]], grad_fn=<PermuteBackward0>) tensor([[0.]])\n",
            "tensor([[61.7519]], grad_fn=<PermuteBackward0>) tensor([[69.]])\n",
            "tensor([[42.4162]], grad_fn=<PermuteBackward0>) tensor([[57.]])\n",
            "tensor([[3.8238]], grad_fn=<PermuteBackward0>) tensor([[0.]])\n",
            "tensor([[-220.4406]], grad_fn=<PermuteBackward0>) tensor([[-671.]])\n",
            "tensor([[835.4326]], grad_fn=<PermuteBackward0>) tensor([[943.]])\n",
            "tensor([[-278.6243]], grad_fn=<PermuteBackward0>) tensor([[-770.]])\n",
            "tensor([[572.1341]], grad_fn=<PermuteBackward0>) tensor([[552.]])\n",
            "tensor([[50.0655]], grad_fn=<PermuteBackward0>) tensor([[78.]])\n",
            "tensor([[731.2491]], grad_fn=<PermuteBackward0>) tensor([[805.]])\n",
            "tensor([[3.3850]], grad_fn=<PermuteBackward0>) tensor([[6.]])\n",
            "tensor([[3.8632]], grad_fn=<PermuteBackward0>) tensor([[-6.]])\n",
            "tensor([[12.9732]], grad_fn=<PermuteBackward0>) tensor([[31.]])\n",
            "tensor([[43.6059]], grad_fn=<PermuteBackward0>) tensor([[53.]])\n",
            "tensor([[-215.3538]], grad_fn=<PermuteBackward0>) tensor([[-677.]])\n",
            "tensor([[358.0397]], grad_fn=<PermuteBackward0>) tensor([[253.]])\n",
            "tensor([[46.0982]], grad_fn=<PermuteBackward0>) tensor([[21.]])\n",
            "tensor([[3.8807]], grad_fn=<PermuteBackward0>) tensor([[5.]])\n",
            "tensor([[3.9308]], grad_fn=<PermuteBackward0>) tensor([[7.]])\n",
            "tensor([[206.8335]], grad_fn=<PermuteBackward0>) tensor([[239.]])\n",
            "tensor([[64.0167]], grad_fn=<PermuteBackward0>) tensor([[68.]])\n",
            "tensor([[42.6601]], grad_fn=<PermuteBackward0>) tensor([[-83.]])\n",
            "Testing Loss:  89.04827377319336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "print(avg_val_loss)\n",
        "plt.plot(avg_val_loss,label = \"Val loss\")\n",
        "plt.plot(tr_loss_hist,label = \"Train loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "iIucRWGOP2zQ",
        "outputId": "1a26032e-903d-460c-d4af-9a5293d1cb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[116.40690612792969, 97.07472229003906, 86.08900451660156, 100.45944213867188, 105.84500122070312, 73.92386627197266, 75.3816909790039, 90.26432800292969, 67.86396026611328, 67.1230697631836, 85.47012329101562, 84.36009216308594, 79.07967376708984, 105.94126892089844, 85.95511627197266, 82.20992279052734, 96.68620300292969, 105.21898651123047, 104.32254791259766, 69.22174072265625, 103.23612976074219, 88.18685913085938, 73.77986907958984, 87.15571594238281, 87.29093170166016, 86.69891357421875, 88.49838256835938, 71.73114013671875, 80.19339752197266, 75.4971694946289, 86.04631805419922, 106.73442840576172, 95.76499938964844, 78.83285522460938, 85.38690185546875, 88.41508483886719, 76.56358337402344, 90.1668701171875, 87.41426086425781, 90.76940155029297, 69.48397064208984, 87.03263854980469, 94.20161437988281, 107.88783264160156, 100.16096496582031, 119.01901245117188, 90.57124328613281, 101.61531066894531, 93.77882385253906, 81.40139770507812]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat"
      ],
      "metadata": {
        "id": "RZXQIzZXN5c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RUh_T6W6OIgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MLP Implementation"
      ],
      "metadata": {
        "id": "844wX8qtbujM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2,l1\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import AUC\n",
        "from tensorflow.keras.initializers import GlorotNormal\n",
        "import keras_tuner as kt\n",
        "\n",
        "def model_builder():\n",
        "  model=Sequential()\n",
        "  model.add(Dense(7,input_shape=(7,),activation='relu',kernel_initializer = GlorotNormal()))\n",
        "  # model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.15))\n",
        "  # model.add(Dense(16,activation='relu',kernel_regularizer=l2(0.001)))\n",
        "  model.add(Dense(64,activation='relu',kernel_initializer = GlorotNormal()))\n",
        "  # model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.3))\n",
        "  model.add(Dense(32,activation='relu',kernel_initializer = GlorotNormal()))\n",
        "  model.add(Dense(8,activation='relu',kernel_initializer = GlorotNormal()))\n",
        "  # model.add(BatchNormalization())\n",
        "  # model.add(Dropout(0.2))\n",
        "  model.add(Dense(1))\n",
        "  # hp_learning_rate = hp.Choice('learning_rate', values=[0.01,0.001,0.0001,0.00001])\n",
        "  # optimizer = Adam(lr=0.01, decay=5e-4)\n",
        "  optimizer = Adam(lr=0.02)\n",
        "  model.compile(optimizer=optimizer, loss='mae')\n",
        "  return model\n",
        "# history=model.fit(X, y, epochs=70, validation_split=0.2, batch_size=8)"
      ],
      "metadata": {
        "id": "5ArwqB7abyeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X,X_test,y,y_test=train_test_split(X,y,shuffle=True,test_size=0.1)"
      ],
      "metadata": {
        "id": "eu6KajcJTNMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=model_builder()\n",
        "history = model.fit(X, y, epochs=60, validation_split=0.2, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rECulHR1chVx",
        "outputId": "f56be334-59e1-4160-d146-2a665c68edb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "810/810 [==============================] - 3s 3ms/step - loss: 205.2912 - val_loss: 180.2156\n",
            "Epoch 2/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 167.3069 - val_loss: 125.3339\n",
            "Epoch 3/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 70.9437 - val_loss: 45.0572\n",
            "Epoch 4/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 30.6064 - val_loss: 23.1842\n",
            "Epoch 5/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 27.4832 - val_loss: 19.4870\n",
            "Epoch 6/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 23.6713 - val_loss: 18.5387\n",
            "Epoch 7/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 21.8057 - val_loss: 24.0340\n",
            "Epoch 8/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 19.0844 - val_loss: 21.4603\n",
            "Epoch 9/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 34.2444 - val_loss: 21.8358\n",
            "Epoch 10/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 18.4702 - val_loss: 18.3028\n",
            "Epoch 11/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 23.9195 - val_loss: 14.1182\n",
            "Epoch 12/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 16.2300 - val_loss: 15.7513\n",
            "Epoch 13/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 20.0792 - val_loss: 17.4947\n",
            "Epoch 14/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 15.3049 - val_loss: 14.0924\n",
            "Epoch 15/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 14.8870 - val_loss: 19.7312\n",
            "Epoch 16/60\n",
            "810/810 [==============================] - 3s 3ms/step - loss: 17.6481 - val_loss: 11.4848\n",
            "Epoch 17/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 14.2999 - val_loss: 12.8016\n",
            "Epoch 18/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 14.1250 - val_loss: 11.4818\n",
            "Epoch 19/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 45.3477 - val_loss: 31.6236\n",
            "Epoch 20/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 23.7834 - val_loss: 16.6474\n",
            "Epoch 21/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 19.3748 - val_loss: 16.0952\n",
            "Epoch 22/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 17.4111 - val_loss: 14.6898\n",
            "Epoch 23/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 17.0111 - val_loss: 19.1725\n",
            "Epoch 24/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 16.8072 - val_loss: 20.9749\n",
            "Epoch 25/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 16.0669 - val_loss: 11.4863\n",
            "Epoch 26/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 15.0828 - val_loss: 14.3573\n",
            "Epoch 27/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 14.6461 - val_loss: 15.4427\n",
            "Epoch 28/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 13.8845 - val_loss: 11.9918\n",
            "Epoch 29/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 13.9428 - val_loss: 12.4383\n",
            "Epoch 30/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 14.0262 - val_loss: 12.0839\n",
            "Epoch 31/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 13.4968 - val_loss: 13.1753\n",
            "Epoch 32/60\n",
            "810/810 [==============================] - 3s 4ms/step - loss: 13.7407 - val_loss: 12.7363\n",
            "Epoch 33/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 13.6750 - val_loss: 10.4120\n",
            "Epoch 34/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 13.2534 - val_loss: 8.4713\n",
            "Epoch 35/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 12.4456 - val_loss: 10.8783\n",
            "Epoch 36/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 12.3112 - val_loss: 12.2705\n",
            "Epoch 37/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 12.6762 - val_loss: 14.1143\n",
            "Epoch 38/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.9732 - val_loss: 9.2278\n",
            "Epoch 39/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 12.4820 - val_loss: 11.7683\n",
            "Epoch 40/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.5420 - val_loss: 6.6505\n",
            "Epoch 41/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.8091 - val_loss: 8.6281\n",
            "Epoch 42/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.3471 - val_loss: 9.9400\n",
            "Epoch 43/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.3939 - val_loss: 8.1729\n",
            "Epoch 44/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.2656 - val_loss: 11.9324\n",
            "Epoch 45/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 9.4773 - val_loss: 11.3526\n",
            "Epoch 46/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.0554 - val_loss: 21.2481\n",
            "Epoch 47/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 10.4689 - val_loss: 10.1498\n",
            "Epoch 48/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 10.6957 - val_loss: 11.7322\n",
            "Epoch 49/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 10.0944 - val_loss: 7.7440\n",
            "Epoch 50/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.7317 - val_loss: 10.1439\n",
            "Epoch 51/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 10.1606 - val_loss: 9.5711\n",
            "Epoch 52/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 9.2858 - val_loss: 9.8579\n",
            "Epoch 53/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 16.2527 - val_loss: 11.4213\n",
            "Epoch 54/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 8.9461 - val_loss: 6.8947\n",
            "Epoch 55/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 9.5491 - val_loss: 11.7662\n",
            "Epoch 56/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 10.9089 - val_loss: 9.0986\n",
            "Epoch 57/60\n",
            "810/810 [==============================] - 2s 3ms/step - loss: 9.6281 - val_loss: 9.9063\n",
            "Epoch 58/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 8.5568 - val_loss: 7.2187\n",
            "Epoch 59/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 8.3647 - val_loss: 7.4590\n",
            "Epoch 60/60\n",
            "810/810 [==============================] - 2s 2ms/step - loss: 11.7121 - val_loss: 7.1486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_loss_hist=history.history['loss']\n",
        "avg_val_loss=history.history['val_loss']\n",
        "from matplotlib import pyplot as plt\n",
        "plt.plot(avg_val_loss,label = \"Val loss\")\n",
        "plt.plot(tr_loss_hist,label = \"Train loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5Ic7fGC1co54",
        "outputId": "7c72730a-9507-4c85-dd51-3eb78510989a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat=model.predict(X_test)\n",
        "# print(yhat[:10],y_test[:10])\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "score = r2_score(y_test, yhat)\n",
        "mse_loss=mean_absolute_error(y_test, yhat)\n",
        "score,mse_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpjsahZHc267",
        "outputId": "0a032fdb-8c26-41ed-9e35-7e5d652c6807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9993223135663057, 7.149539991948339)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYVLQzRoUapX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}