{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "866f022aee864f1caa2d8b099ed0d06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1ebaa49d9734529bf0a2c68aeeaa1be",
              "IPY_MODEL_04988fbd734c4058b56f3f13d9b1c7a2",
              "IPY_MODEL_58eed334fc944deda3fea8e4c3ebe78d"
            ],
            "layout": "IPY_MODEL_3b94f11fc98547a787b01d4e009a2082"
          }
        },
        "e1ebaa49d9734529bf0a2c68aeeaa1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ec66c505b4a4fbc9cf82f245c9b94ca",
            "placeholder": "​",
            "style": "IPY_MODEL_4ee5d599f485462f99394e2d4b56c7d0",
            "value": "100%"
          }
        },
        "04988fbd734c4058b56f3f13d9b1c7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3ad346cab15443aa4b404826d6420cc",
            "max": 7165,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_962e145bc0d3495eafd91fba783fb342",
            "value": 7165
          }
        },
        "58eed334fc944deda3fea8e4c3ebe78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a081051cf23482c81ed2a9b6e993ea3",
            "placeholder": "​",
            "style": "IPY_MODEL_32e4254db6de49649ddd647767f165a9",
            "value": " 7165/7165 [00:05&lt;00:00, 1108.38it/s]"
          }
        },
        "3b94f11fc98547a787b01d4e009a2082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec66c505b4a4fbc9cf82f245c9b94ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ee5d599f485462f99394e2d4b56c7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3ad346cab15443aa4b404826d6420cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "962e145bc0d3495eafd91fba783fb342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a081051cf23482c81ed2a9b6e993ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32e4254db6de49649ddd647767f165a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZklQrH1L0Zsd"
      },
      "outputs": [],
      "source": [
        "# ====================================================\n",
        "# CFG: Configuration settings\n",
        "# ====================================================\n",
        "class CFG:\n",
        "    wandb=False\n",
        "    competition='FB3'\n",
        "    _wandb_kernel='nakama'\n",
        "    debug=False\n",
        "    apex=True\n",
        "    print_freq=20\n",
        "    num_workers=4\n",
        "    model=\"microsoft/deberta-v3-base\"\n",
        "    gradient_checkpointing=True\n",
        "    scheduler='cosine' # ['linear', 'cosine']\n",
        "    batch_scheduler=True\n",
        "    num_cycles=0.5\n",
        "    num_warmup_steps=0\n",
        "    epochs=4\n",
        "    encoder_lr=2e-5\n",
        "    decoder_lr=2e-5\n",
        "    min_lr=1e-6\n",
        "    eps=1e-6\n",
        "    betas=(0.9, 0.999)\n",
        "    batch_size=8\n",
        "    max_len=512\n",
        "    weight_decay=0.01\n",
        "    gradient_accumulation_steps=1\n",
        "    max_grad_norm=1000\n",
        "    target_cols=['content', 'wording']\n",
        "    seed=42\n",
        "    n_fold=4\n",
        "    trn_fold=[0, 1, 2, 3]\n",
        "    train=True\n",
        "\n",
        "if CFG.debug:\n",
        "    CFG.epochs = 2\n",
        "    CFG.trn_fold = [0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import re\n",
        "import ast\n",
        "import sys\n",
        "import copy\n",
        "import json\n",
        "import time\n",
        "import math\n",
        "import string\n",
        "import pickle\n",
        "import random\n",
        "import itertools\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
        "\n",
        "os.system('pip install iterative-stratification==0.1.7')\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "os.system('pip install -q transformers')\n",
        "os.system('pip install -q tokenizers')\n",
        "os.system('pip install -q sentencepiece')\n",
        "import tokenizers\n",
        "import transformers\n",
        "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
        "print(f\"transformers.__version__: {transformers.__version__}\")\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
        "%env TOKENIZERS_PARALLELISM=true\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn7aVvOg0kxh",
        "outputId": "0689e463-cb11-4d55-9600-ffa974e589c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizers.__version__: 0.13.3\n",
            "transformers.__version__: 4.31.0\n",
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "seed_everything(seed=42)"
      ],
      "metadata": {
        "id": "X9fEEVxP0vlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train=pd.read_csv(\"/content/train_df.csv\")\n",
        "test=pd.read_csv(\"/content/test_df.csv\")\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "f3P2AXra0_S5",
        "outputId": "27a09927-4dcd-458e-a261-1bf78074c8ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     student_id prompt_id                                               text   content   wording  summary_length                                 fixed_summary_text                                    prompt_question               prompt_title                                        prompt_text  prompt_length                                              input\n",
              "0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...  0.205683  0.380538              64  The third wave was an experimental see how peo...  Summarize how the Third Wave developed over su...             The Third Wave  Background \\r\\nThe Third Wave experiment took ...            660  The Third Wave[SEP]Summarize how the Third Wav...\n",
              "1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme... -0.548304  0.506755              54  They would rub it up with soda to make the sme...  Summarize the various ways the factory would u...    Excerpt from The Jungle  With one member trimming beef in a cannery, an...           1076  Excerpt from The Jungle[SEP]Summarize the vari...\n",
              "2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...  3.128928  4.231226             269  In Egypt, there were many occupations and soci...  In complete sentences, summarize the structure...  Egyptian Social Structure  Egyptian society was structured like a pyramid...            625  Egyptian Social Structure[SEP]In complete sent...\n",
              "3  005ab0199905    3b9047  The highest class was Pharaohs these people we... -0.210614 -0.471415              28  The highest class was Pharaohs these people we...  In complete sentences, summarize the structure...  Egyptian Social Structure  Egyptian society was structured like a pyramid...            625  Egyptian Social Structure[SEP]In complete sent...\n",
              "4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...  3.272894  3.219757             232  The Third Wave developed  rapidly because the ...  Summarize how the Third Wave developed over su...             The Third Wave  Background \\r\\nThe Third Wave experiment took ...            660  The Third Wave[SEP]Summarize how the Third Wav..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d848a3fa-ac79-469d-84ed-8cc3690f723e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>summary_length</th>\n",
              "      <th>fixed_summary_text</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "      <th>prompt_length</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000e8c3c7ddb</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>64</td>\n",
              "      <td>The third wave was an experimental see how peo...</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>The Third Wave[SEP]Summarize how the Third Wav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0020ae56ffbf</td>\n",
              "      <td>ebad26</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>-0.548304</td>\n",
              "      <td>0.506755</td>\n",
              "      <td>54</td>\n",
              "      <td>They would rub it up with soda to make the sme...</td>\n",
              "      <td>Summarize the various ways the factory would u...</td>\n",
              "      <td>Excerpt from The Jungle</td>\n",
              "      <td>With one member trimming beef in a cannery, an...</td>\n",
              "      <td>1076</td>\n",
              "      <td>Excerpt from The Jungle[SEP]Summarize the vari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>004e978e639e</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>3.128928</td>\n",
              "      <td>4.231226</td>\n",
              "      <td>269</td>\n",
              "      <td>In Egypt, there were many occupations and soci...</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>Egyptian Social Structure[SEP]In complete sent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>005ab0199905</td>\n",
              "      <td>3b9047</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>-0.210614</td>\n",
              "      <td>-0.471415</td>\n",
              "      <td>28</td>\n",
              "      <td>The highest class was Pharaohs these people we...</td>\n",
              "      <td>In complete sentences, summarize the structure...</td>\n",
              "      <td>Egyptian Social Structure</td>\n",
              "      <td>Egyptian society was structured like a pyramid...</td>\n",
              "      <td>625</td>\n",
              "      <td>Egyptian Social Structure[SEP]In complete sent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0070c9e7af47</td>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>232</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
              "      <td>660</td>\n",
              "      <td>The Third Wave[SEP]Summarize how the Third Wav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d848a3fa-ac79-469d-84ed-8cc3690f723e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d848a3fa-ac79-469d-84ed-8cc3690f723e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d848a3fa-ac79-469d-84ed-8cc3690f723e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10be8b88-1b4e-4df9-b83e-e9ff8a43d966\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10be8b88-1b4e-4df9-b83e-e9ff8a43d966')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10be8b88-1b4e-4df9-b83e-e9ff8a43d966 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
        "# tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n",
        "CFG.tokenizer = tokenizer\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ1S9-zJ1U4J",
        "outputId": "8c0e2d97-163e-4243-d568-14019c3f50fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2TokenizerFast(name_or_path='microsoft/deberta-v3-base', vocab_size=128000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = []\n",
        "tk0 = tqdm(train['text'].fillna(\"\").values, total=len(train))\n",
        "for text in tk0:\n",
        "    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n",
        "    lengths.append(length)\n",
        "CFG.max_len = max(lengths) + 2 # cls & sep\n",
        "CFG.max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "866f022aee864f1caa2d8b099ed0d06c",
            "e1ebaa49d9734529bf0a2c68aeeaa1be",
            "04988fbd734c4058b56f3f13d9b1c7a2",
            "58eed334fc944deda3fea8e4c3ebe78d",
            "3b94f11fc98547a787b01d4e009a2082",
            "6ec66c505b4a4fbc9cf82f245c9b94ca",
            "4ee5d599f485462f99394e2d4b56c7d0",
            "a3ad346cab15443aa4b404826d6420cc",
            "962e145bc0d3495eafd91fba783fb342",
            "2a081051cf23482c81ed2a9b6e993ea3",
            "32e4254db6de49649ddd647767f165a9"
          ]
        },
        "id": "VJkoD5V11U1S",
        "outputId": "b29f663d-8f28-4cb5-d642-f835c4aed1ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7165 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "866f022aee864f1caa2d8b099ed0d06c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "822"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset\n",
        "\n",
        "def tokenize_data(cfg,data):\n",
        "  tokenized_data= cfg.tokenizer.encode_plus(data,max_length=cfg.max_len,pad_to_max_length=True,\n",
        "                                            truncation=True,\n",
        "                                            )\n",
        "  for k,v in tokenized_data.items():\n",
        "    tokenized_data[k]=torch.tensor(v, dtype=torch.long)\n",
        "  return tokenized_data\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "  def __init__(self,cfg,df):\n",
        "    self.texts=df['input'].values\n",
        "    self.labels=df[cfg.target_cols].values\n",
        "    self.cfg=cfg\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self,item):\n",
        "    inputs = tokenize_data(self.cfg, self.texts[item])\n",
        "    label = torch.tensor(self.labels[item], dtype=torch.float)\n",
        "    return inputs,label\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "  def __init__(self,cfg,df):\n",
        "    self.texts=df['text'].values\n",
        "    self.cfg=cfg\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self,item):\n",
        "    inputs = tokenize_data(self.cfg, self.texts[item])\n",
        "    return inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "EOnVhYC41UyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MCRMSE(y_trues, y_preds):\n",
        "    scores = []\n",
        "    idxes = y_trues.shape[1]\n",
        "    for i in range(idxes):\n",
        "        y_true = y_trues[:,i]\n",
        "        y_pred = y_preds[:,i]\n",
        "        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n",
        "        scores.append(score)\n",
        "    mcrmse_score = np.mean(scores)\n",
        "    return mcrmse_score, scores\n",
        "\n",
        "\n",
        "def get_score(y_trues, y_preds):\n",
        "    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n",
        "    return mcrmse_score, scores"
      ],
      "metadata": {
        "id": "ftXag5ESp57t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeanPooling(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MeanPooling,self).__init__()\n",
        "\n",
        "  def forward(self,last_hidden_state,attention_mask):\n",
        "    # print(\"last_hidden_state: \",last_hidden_state.size())\n",
        "    # print(\"attention_mask: \",attention_mask.size())\n",
        "    masked_values=attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
        "    # print(\"masked_values: \",masked_values.size())\n",
        "    embeddings=torch.sum(last_hidden_state*masked_values,1)\n",
        "    # print(\"embeddings: \",embeddings.size())\n",
        "    sum_mask=torch.clamp(masked_values.sum(1),min=1e-9)\n",
        "    # print(\"sum_mask: \",sum_mask.size())\n",
        "    return embeddings/sum_mask\n",
        "\n",
        "def collate(inputs):\n",
        "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
        "    for k, v in inputs.items():\n",
        "        inputs[k] = inputs[k][:,:mask_len]\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "0HoyUi2i1Uuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use DeBerta model which are build on our basic transformer model like BERT but have some more features like:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. Enhanced MLM: where instead of masking random token, this model masks a span of tokens, this method is called Span boundary objective(SBO), It masks consecutive spans of tokens, which helps the model capture dependencies across multiple tokens and better understand long range relationships\n",
        "2. Intra sentence and inter sentence relationship: Apart from normal intra sentence(within a single sentence) relation, this model also takes into consideration the relation between two different sentences(inter sentence learning) which allows the model to understand document-level semantics and capture global context effectively.\n",
        "3. Contrastive birectional training\n",
        "4. Cross layer parameter sharing: By sharing params, DeBERTa reduces the number of total params, making it a more computationally scalable and memory efficient model."
      ],
      "metadata": {
        "id": "n9q_J4yEvjr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
        "        self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
        "\n",
        "        if self.cfg.gradient_checkpointing:\n",
        "            self.model.gradient_checkpointing_enable()\n",
        "\n",
        "        self.pool = MeanPooling()\n",
        "        self.fc = nn.Linear(self.config.hidden_size, 2)\n",
        "        self._init_weights(self.fc)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def feature(self, inputs):\n",
        "        outputs = self.model(**inputs)\n",
        "        last_hidden_states = outputs[0]\n",
        "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
        "        # print(\"Mean embedding: \",feature)\n",
        "        return feature\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        feature = self.feature(inputs)\n",
        "        output = self.fc(feature)\n",
        "        return output"
      ],
      "metadata": {
        "id": "x0HaLSd_5eYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
        "    model.train()\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
        "    losses = []\n",
        "    start = end = time.time()\n",
        "    global_step = 0\n",
        "    for step, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
        "            y_preds = model(inputs)\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.append(loss.item())\n",
        "        scaler.scale(loss).backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
        "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "            if CFG.batch_scheduler:\n",
        "                scheduler.step()\n",
        "        end = time.time()\n",
        "        # if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
        "        #     print(f'Epoch: {epoch+1},{step},{len(train_loader)}')\n",
        "        #     # print(f'Loss: {losses},{np.mean(losses)} ')\n",
        "        #     print(f'Loss:{np.mean(losses)} ')\n",
        "\n",
        "    return np.mean(losses)\n",
        "\n",
        "\n",
        "def valid_fn(valid_loader, model, criterion, device):\n",
        "    losses = []#AverageMeter()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "    for step, (inputs, labels) in enumerate(valid_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        labels = labels.to(device)\n",
        "        batch_size = labels.size(0)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs)\n",
        "            loss = criterion(y_preds, labels)\n",
        "        if CFG.gradient_accumulation_steps > 1:\n",
        "            loss = loss / CFG.gradient_accumulation_steps\n",
        "        losses.append(loss.item())\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "        end = time.time()\n",
        "        # if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
        "        #     print(f'EVAL: [{step}/{len(valid_loader)}] ')\n",
        "        #     # print(f'Loss: {losses},({np.mean(losses)}) ')\n",
        "        #     print(f'Loss:{np.mean(losses)} ')\n",
        "\n",
        "    predictions = np.concatenate(preds)\n",
        "    return np.mean(losses), predictions\n",
        "\n",
        "def test_fn(test_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    start = end = time.time()\n",
        "    for step, inputs in enumerate(test_loader):\n",
        "        inputs = collate(inputs)\n",
        "        for k, v in inputs.items():\n",
        "            inputs[k] = v.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_preds = model(inputs)\n",
        "        preds.append(y_preds.to('cpu').numpy())\n",
        "        end = time.time()\n",
        "    predictions = np.concatenate(preds)\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "MuYCCrPq9ZjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# train loop\n",
        "# ====================================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, valid_df = train_test_split(train, test_size=0.2, random_state=42)\n",
        "\n",
        "def train_loop(train_df,valid_df):\n",
        "\n",
        "    train_folds = train_df\n",
        "    valid_folds = valid_df\n",
        "\n",
        "    valid_labels = valid_folds[CFG.target_cols].values\n",
        "\n",
        "    train_dataset = TrainDataset(CFG, train_folds)\n",
        "    valid_dataset = TrainDataset(CFG, valid_folds)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=True,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_dataset,\n",
        "                              batch_size=CFG.batch_size * 2,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "\n",
        "    # ====================================================\n",
        "    # model & optimizer\n",
        "    # ====================================================\n",
        "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
        "    # torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
        "    model.to(device)\n",
        "\n",
        "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
        "        param_optimizer = list(model.named_parameters())\n",
        "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_parameters = [\n",
        "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
        "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
        "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
        "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        return optimizer_parameters\n",
        "\n",
        "    optimizer_parameters = get_optimizer_params(model,\n",
        "                                                encoder_lr=CFG.encoder_lr,\n",
        "                                                decoder_lr=CFG.decoder_lr,\n",
        "                                                weight_decay=CFG.weight_decay)\n",
        "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
        "\n",
        "    # ====================================================\n",
        "    # scheduler\n",
        "    # ====================================================\n",
        "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
        "        if cfg.scheduler == 'linear':\n",
        "            scheduler = get_linear_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
        "            )\n",
        "        elif cfg.scheduler == 'cosine':\n",
        "            scheduler = get_cosine_schedule_with_warmup(\n",
        "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
        "            )\n",
        "        return scheduler\n",
        "\n",
        "    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n",
        "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
        "\n",
        "    # ====================================================\n",
        "    # loop\n",
        "    # ====================================================\n",
        "    criterion = nn.SmoothL1Loss(reduction='mean') # RMSELoss(reduction=\"mean\")\n",
        "\n",
        "    best_score = np.inf\n",
        "\n",
        "    for epoch in range(CFG.epochs):\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # train\n",
        "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
        "        print(\"training loss: \",avg_loss)\n",
        "\n",
        "        # eval\n",
        "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
        "        print(\"Validation loss: \",avg_val_loss)\n",
        "        print(\"Predictions: \",predictions)\n",
        "\n",
        "        # scoring\n",
        "        score, scores = get_score(valid_labels, predictions)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(\"Elapsed time: \",elapsed)\n",
        "    torch.save(model.state_dict(), 'deberta_model.pth')\n",
        "    return predictions\n",
        "\n",
        "predictions=train_loop(train_df,valid_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1ULZPp9Aatb",
        "outputId": "dd07f33d-a6a2-4e52-f5d6-a68c76e01981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training loss:  0.16365786648599961\n",
            "Validation loss:  0.12313322756025526\n",
            "Predictions:  [[ 0.6879239   0.66051334]\n",
            " [-0.26996315  0.15082607]\n",
            " [-0.39092517  0.1830393 ]\n",
            " ...\n",
            " [ 0.12343305  0.2360103 ]\n",
            " [ 1.2101552   0.6674766 ]\n",
            " [-1.1247251  -1.6724172 ]]\n",
            "Elapsed time:  286.45826530456543\n",
            "training loss:  0.102467445089539\n",
            "Validation loss:  0.11088406518101693\n",
            "Predictions:  [[ 0.6310376   0.70644265]\n",
            " [-0.3177273   0.19957699]\n",
            " [-0.4435555   0.13019091]\n",
            " ...\n",
            " [-0.05403788  0.07642724]\n",
            " [ 1.552013    0.7875407 ]\n",
            " [-1.0308473  -1.6175041 ]]\n",
            "Elapsed time:  288.0299093723297\n",
            "training loss:  0.08508366966026955\n",
            "Validation loss:  0.10495249610394239\n",
            "Predictions:  [[ 0.5628776   0.63266444]\n",
            " [-0.3007487   0.14491886]\n",
            " [-0.4578308   0.14224549]\n",
            " ...\n",
            " [-0.06799011  0.10578106]\n",
            " [ 1.28895     0.621654  ]\n",
            " [-1.1178125  -1.6625019 ]]\n",
            "Elapsed time:  284.81840658187866\n",
            "training loss:  0.07154476911079284\n",
            "Validation loss:  0.10845416163404782\n",
            "Predictions:  [[ 0.5798184   0.7174115 ]\n",
            " [-0.28474978  0.2092436 ]\n",
            " [-0.443426    0.19409385]\n",
            " ...\n",
            " [-0.04936654  0.07713319]\n",
            " [ 1.3924693   0.673784  ]\n",
            " [-1.0857025  -1.6113474 ]]\n",
            "Elapsed time:  286.05683755874634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model=CustomModel(CFG, config_path=None, pretrained=True)\n",
        "final_model.load_state_dict(torch.load('deberta_model.pth'))\n",
        "final_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEd1z89xBuBK",
        "outputId": "d3d957ea-ad3f-4368-9bed-81512e309499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (model): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): StableDropout()\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): StableDropout()\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): StableDropout()\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): StableDropout()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pool): MeanPooling()\n",
              "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=TestDataset(CFG, test)\n",
        "dataloader=DataLoader(dataset,\n",
        "                              batch_size=CFG.batch_size,\n",
        "                              shuffle=False,\n",
        "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
        "criterion=nn.SmoothL1Loss(reduction='mean')\n",
        "final_model=final_model.to(device)\n",
        "final_predictions = test_fn(dataloader, final_model, criterion, device)"
      ],
      "metadata": {
        "id": "AdPiNMW_yZbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final_predictions),final_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpWASFDH8xHx",
        "outputId": "587d542d-a6e0-4312-ce15-9383f2e7f6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4,\n",
              " array([[-1.4205468, -1.3065829],\n",
              "        [-1.4560364, -1.3117912],\n",
              "        [-1.4212203, -1.2900599],\n",
              "        [-1.4609294, -1.2826453]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_data_df = pd.DataFrame(final_predictions, columns=['content', 'wording'])\n",
        "\n",
        "submission=pd.read_csv(\"/content/drive/MyDrive/Data/EvaluateSummaries/sample_submission.csv\")\n",
        "submission.drop(['content','wording'],axis=1,inplace=True)\n",
        "\n",
        "combined_df = pd.concat([submission, new_data_df], axis=1)"
      ],
      "metadata": {
        "id": "gV-UnOVNyprT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df['wording']=np.round(combined_df['wording'],2)\n",
        "combined_df['content']=np.round(combined_df['content'],2)\n",
        "combined_df.to_csv(\"/content/drive/MyDrive/Data/EvaluateSummaries/my_submission.df\",index=False)\n",
        "combined_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "9zskzze5ywgP",
        "outputId": "f0df47a2-714b-45f1-fba5-a1ddff54aaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     student_id  content  wording\n",
              "0  000000ffffff    -1.42    -1.31\n",
              "1  111111eeeeee    -1.46    -1.31\n",
              "2  222222cccccc    -1.42    -1.29\n",
              "3  333333dddddd    -1.46    -1.28"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77c5528f-2111-411b-9dd8-07b0d5fb4d06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000ffffff</td>\n",
              "      <td>-1.42</td>\n",
              "      <td>-1.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111111eeeeee</td>\n",
              "      <td>-1.46</td>\n",
              "      <td>-1.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>222222cccccc</td>\n",
              "      <td>-1.42</td>\n",
              "      <td>-1.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>333333dddddd</td>\n",
              "      <td>-1.46</td>\n",
              "      <td>-1.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77c5528f-2111-411b-9dd8-07b0d5fb4d06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77c5528f-2111-411b-9dd8-07b0d5fb4d06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77c5528f-2111-411b-9dd8-07b0d5fb4d06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ea82ac78-9aca-4662-a459-19ec48885b4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea82ac78-9aca-4662-a459-19ec48885b4f')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ea82ac78-9aca-4662-a459-19ec48885b4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eQ2-bHuqyxx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i59FqKni2SYN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}